import gradio as gr
import json
import apis
from perception import Perception
from action import Action
from brain import Brain
from lucy_agent import LucyAgent

# æœ¬æ¥åº”è¯¥æ˜¯æä¾›ä¸€äº›ç‰©ä»¶çš„æ¥å£ä¾›agentæŸ¥è¯¢æˆ–æ„ŸçŸ¥ï¼Œç„¶åå†è½¬åŒ–æˆè¿™ç§è‡ªç„¶è¯­è¨€æè¿°ã€‚
# æ¯”å¦‚èƒ¡æ¡ƒæœ¬èº«æœ‰ä¸€ä¸ªä½ç½®å±æ€§ï¼Œåœ¨å¾€ç”Ÿå ‚ï¼Œå°±åº”è¯¥æ„ŸçŸ¥ä¸åˆ°å’–å•¡åº—é‚£è¾¹çš„ä¿¡æ¯ã€‚
# ä½†æ€»çš„æ¥è¯´ï¼Œå†³ç­–è¿˜æ˜¯åŸºäºè‡ªç„¶è¯­è¨€å»åšï¼Œå› è€Œå¯ä»¥è¿™æ ·æ¨¡æ‹Ÿã€‚
# æ‹’ç»å›ç­”å’Œè¡ŒåŠ¨çš„èƒ½åŠ›åŒæ ·é‡è¦ã€‚
# å¯ä»¥æ‹†åˆ†æˆ:xxäº‹ä»¶å‘ç”Ÿ,ç„¶åæ ¹æ®èƒ¡æ¡ƒçš„çŠ¶æ€å’Œä½ç½®åˆ¤æ–­é€»è¾‘ -> è‡ªç„¶è¯­è¨€æè¿°
# æ¯”å¦‚ï¼š
# "å’–å•¡åº—å‰å°ä¿¡æ¯ä¼ æ¥ï¼šhadiç‚¹äº†ä¸€æ¯æ‹¿é“","èƒ¡æ¡ƒåœ¨å¾€ç”Ÿå ‚" -> ä¸è§¦å‘ï¼Œè¿”å›èƒ¡æ¡ƒæ²¡æ„Ÿè§‰åˆ°
# "hadiåœ¨å¾€ç”Ÿå ‚é—¨å£å‘èƒ¡æ¡ƒæ‰“æ‹›å‘¼"ï¼Œ"èƒ¡æ¡ƒåœ¨å¾€ç”Ÿå ‚" -> è§¦å‘å¹¶ç”Ÿæˆæè¿°ï¼šèƒ¡æ¡ƒå¬åˆ°äº†hadiåœ¨æ‰“æ‹›å‘¼ï¼Œçœ‹åˆ°äº†hadiåœ¨å¾€ç”Ÿå ‚é—¨å£ã€‚

hutao_place = "å¾€ç”Ÿå ‚"

EVENTS_LIST = [
    ("hadiåœ¨å¾€ç”Ÿå ‚é—¨å£,å‘èƒ¡æ¡ƒæ‰“æ‹›å‘¼ã€‚", "å¾€ç”Ÿå ‚"),
    ("ç’ƒæœˆç®¡å§”ä¼šå‘èƒ¡æ¡ƒå‘æ¶ˆæ¯,å†…å®¹ä¸ºï¼šå¾€ç”Ÿå ‚ç¬¬ä¸ƒåä¸ƒä»£å ‚ä¸»,æ‚¨å¥½ã€‚è¿‘æ¥ç’ƒæœˆè¦ä¸¾è¡Œä¸€åœºç‰¹åˆ«çš„é€åˆ«ä¹‹ä»ª,è¯·æ‚¨ç€æ‰‹ç­–åˆ’ã€‚", "å…¨å±€"),
    ("hadiåœ¨å’–å•¡åº—å‰å°ç‚¹äº†ä¸€æ¯æ‹¿é“ã€‚", "å’–å•¡åº—"),
    ("èƒ¡æ¡ƒçš„é—¹é’Ÿå“äº†,æŸ¥çœ‹åå‘ç°å¤‡æ³¨ä¸ºï¼šè®°å¾—çœ‹çœ‹ç’ƒæœˆçš„å†å²ä¹¦ï¼", "å…¨å±€")
]

PERCEPTION_LIST = [
    "èƒ¡æ¡ƒå¬åˆ°äº†hadiåœ¨æ‰“æ‹›å‘¼ã€‚",
    "èƒ¡æ¡ƒæ”¶åˆ°äº†ç’ƒæœˆç®¡å§”ä¼šçš„æ¶ˆæ¯,å†…å®¹ä¸ºï¼šå¾€ç”Ÿå ‚ç¬¬ä¸ƒåä¸ƒä»£å ‚ä¸»,æ‚¨å¥½ã€‚è¿‘æ¥ç’ƒæœˆè¦ä¸¾è¡Œä¸€åœºç‰¹åˆ«çš„é€åˆ«ä¹‹ä»ª,è¯·æ‚¨ç€æ‰‹ç­–åˆ’ã€‚",
    "èƒ¡æ¡ƒæ”¶åˆ°äº†å’–å•¡åº—å‰å°ç³»ç»Ÿçš„æ¶ˆæ¯,å†…å®¹ä¸ºï¼šhadiç‚¹äº†ä¸€æ¯æ‹¿é“ã€‚",
    "èƒ¡æ¡ƒå¬åˆ°äº†è‡ªå·±çš„é—¹é’Ÿå“äº†,æŸ¥çœ‹åå‘ç°å¤‡æ³¨ä¸ºï¼šè®°å¾—çœ‹çœ‹ç’ƒæœˆçš„å†å²ä¹¦ï¼"
]

def save_to_file(file_path:str, conversations)-> None:
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(conversations, f, ensure_ascii=False, indent=4)

def load_prompts(json_file: str) -> dict:
    with open(json_file, 'r',encoding='utf-8') as f:
        data = json.load(f)
    return {item['key']: item['prompt'] for item in data}

def save_agent_json(agent_brain):
    # å­˜åˆ°â€œä¸­æ–‡name.jsonâ€å½“ä¸­ï¼Œä¸å½±å“ç”¨æ¥åˆå§‹åŒ–çš„æ–‡ä»¶
    name = agent_brain.name
    file_path = f"../resource/{name}.json"
    # ç”¨æ¥ä¿®æ”¹åˆå§‹åŒ–æ–‡ä»¶
    # file_path = f"../resource/hutao.json"
    try:
        with open(file_path, "w", encoding="utf-8") as json_file:
            json.dump(agent_brain.to_json(), json_file, indent=4, ensure_ascii=False)
    except IOError:
        print("æ— æ³•å†™å…¥æ–‡ä»¶ã€‚")

if __name__ == "__main__":
    # ç”¨åˆå§‹jsonè¿›è¡Œåˆå§‹åŒ–
    with open("../resource/hutao.json", "r", encoding="utf-8") as json_file:
        loaded_data = json.load(json_file)

    perception = Perception()
    action = Action()
    hutao = LucyAgent(perception=perception, brain=Brain.from_json(loaded_data), action=action)

    # åˆ›å»ºä¸€ä¸ª Gradio ç•Œé¢
    with gr.Blocks() as demo:

        # åˆ›å»ºä¸€ä¸ªçŠ¶æ€å¯¹è±¡ï¼Œç”¨äºå­˜å‚¨å†å²è®°å½•
        state = gr.State([])

        with gr.Tab("å’Œèƒ¡æ¡ƒäº’åŠ¨ï¼\U0001F917"):
            def show_action_state():
                scene_path = ""
                if hutao.brain.fsm.action_state == "ä¼‘æ¯":
                    scene_path = "../resource/pictures/hutao_xiuxi.webp"
                if hutao.brain.fsm.action_state == "çœ‹ä¹¦":
                    scene_path = "../resource/pictures/hutao_kanshu.webp"
                if hutao.brain.fsm.action_state == "ç­–åˆ’å¾€ç”Ÿå ‚ç›¸å…³æ´»åŠ¨":
                    scene_path = "../resource/pictures/hutao_cehua.jpg"
                if hutao.brain.fsm.action_state == "åšå’–å•¡å¹¶é€’äº¤ç»™å®¢æˆ·":
                    scene_path = "../resource/pictures/hutao_coffee.jpg"
                if hutao.brain.fsm.action_state == "å›å¤é—®é¢˜å’ŒèŠå¤©":
                    scene_path = "../resource/pictures/hutao_yao.webp"
                return f"èƒ¡æ¡ƒæ­£åœ¨{hutao.brain.fsm.action_state}", scene_path

            def perceive_and_change_action(trigger):
                if not trigger:
                    return "ä¸‹æ‹‰èœå•ä¸ºç©ºæˆ–æ²¡æœ‰æ¥æ”¶åˆ°ä¸‹æ‹‰èœå•çš„å€¼", "../resource/pictures/hutao_naohuo.webp"

                old_action_state = hutao.brain.fsm.action_state
                thought = hutao.brain.create_thought_from_perception(trigger)
                hutao.brain.fsm.action_state_transition(trigger, thought)
                action_state_str, scene_path = show_action_state()
                action_state_str = (f"èƒ¡æ¡ƒåŸå…ˆæ­£åœ¨{old_action_state},å› ä¸º{trigger}èƒ¡æ¡ƒè®¤ä¸º:{thought}"
                                    f"\n\nå› è€Œå†³å®š{hutao.brain.fsm.action_state}")

                memory = hutao.brain.create_memory(trigger, f"èƒ¡æ¡ƒè¿›è¡Œäº†æ€è€ƒï¼š{thought}")
                hutao.brain.add_memory(memory)
                save_agent_json(hutao.brain)

                print(action_state_str)
                return action_state_str, scene_path

            state_box = gr.Textbox(label="èƒ¡æ¡ƒçš„è¡ŒåŠ¨æƒ…å†µğŸš´â€â™‚ï¸")
            image_box = gr.Image(label="èƒ¡æ¡ƒæ­£åœ¨å¹²ä»€ä¹ˆï¼Ÿ\U0001F60A", height=300)
            query_button = gr.Button("æŸ¥è¯¢èƒ¡æ¡ƒçš„è¡ŒåŠ¨æƒ…å†µğŸ¤¶")
            query_button.click(show_action_state, inputs=[], outputs=[state_box, image_box])

            events_dropdown = gr.Dropdown(choices=PERCEPTION_LIST,
                                          label="å¯ä»¥æ¨¡æ‹Ÿçš„äº‹ä»¶åˆ—è¡¨ğŸ§,ä¹Ÿå¯ä»¥è¯•è¯•è‡ªå·±å†™ï¼",
                                          allow_custom_value=True)
            event_button = gr.Button("æ¨¡æ‹Ÿä¸€äº›äº‹ä»¶çš„å‘ç”Ÿâš¡")
            event_button.click(perceive_and_change_action, inputs=events_dropdown, outputs=[state_box, image_box])

        with gr.Tab("å’Œèƒ¡æ¡ƒå¯¹è¯ï¼ğŸ¥³"):
            def talk_with_hutao(query, history=None):
                if hutao.brain.fsm.action_state != "å›å¤é—®é¢˜å’ŒèŠå¤©":
                    action_state_str, scene_path = show_action_state()
                    return f"{action_state_str},æ²¡æ³•å›å¤ä½ å˜,è¯·å»ç¬¬ä¸€ä¸ªæ ‡ç­¾é¡µæ”¹å˜èƒ¡æ¡ƒçŠ¶æ€", "../resource/audios/è¿™æ˜¯ä¸€æ®µæµ‹è¯•éŸ³é¢‘å“Ÿ.wav", scene_path
                if not query:
                    return f"è¯·ä¸è¦ä¸è¯´è¯å˜", "../resource/audios/è¿™æ˜¯ä¸€æ®µæµ‹è¯•éŸ³é¢‘å“Ÿ.wav", "../resource/pictures/hutao_naohuo.webp"
                if history is None:
                    history = []
                response, history, thought = hutao.brain.cot_chat(query, history)

                input = f"èƒ¡æ¡ƒæ”¶åˆ°äº†æ¥è‡ªhadiçš„è¯¢é—®ï¼š{query}"
                output = f"è¿›è¡Œäº†æ€è€ƒï¼š{thought},åšå‡ºäº†å›å¤ï¼š{response}"
                memory = hutao.brain.create_memory(input,output)
                hutao.brain.add_memory(memory)

                history_text = ""  # åˆå§‹åŒ–å†å²è®°å½•æ–‡æœ¬
                for chat in history:  # éå†å†å²è®°å½•
                    history_text = history_text + chat + "\n"
                save_to_file("../resource/conversations.json", history)

                # è·å–å¿ƒæƒ…é©±åŠ¨çš„è¡¨æƒ…åŒ…
                hutao.brain.fsm.mood_transition(input, thought)
                image_path = hutao.brain.fsm.get_current_emoji()

                # ç”Ÿæˆå“åº”çš„éŸ³é¢‘
                audio_file_path = apis.genshin_tts(text=response.lstrip("èƒ¡æ¡ƒ:"), speaker="èƒ¡æ¡ƒ")

                if not audio_file_path:
                    default_audio_path = "../resource/audios/è¿™æ˜¯ä¸€æ®µæµ‹è¯•éŸ³é¢‘å“Ÿ.wav"
                    audio_file_path = default_audio_path

                save_agent_json(hutao.brain)

                return history_text, audio_file_path, image_path  # è¿”å›å†å²è®°å½•æ–‡æœ¬å’ŒéŸ³é¢‘æ–‡ä»¶è·¯å¾„

            with gr.Row():
                with gr.Column():
                    # åˆ›å»ºä¸€ä¸ªç”¨äºæ˜¾ç¤ºå†å²è®°å½•çš„æ–‡æœ¬æ¡†
                    history_box = gr.Textbox(lines=10, label="å¯¹è¯å†å²è®°å½•\U0001F4DD")
                    # åˆ›å»ºä¸€ä¸ªæ–‡æœ¬æ¡†ï¼Œç”¨äºè¾“å…¥æ–‡æœ¬
                    txt = gr.Textbox(show_label=False, placeholder="è¾“å…¥æ–‡æœ¬,ä¾‹å¦‚\"èƒ¡æ¡ƒå¯ä»¥ç»™æˆ‘æ¥ä¸€æ¯å’–å•¡å—ï¼Ÿ\"\U0001F4AC")

                with gr.Column():
                    # åˆ›å»ºä¸€ä¸ªéŸ³é¢‘æ’­æ”¾å™¨
                    audio_box = gr.Audio(label="èƒ¡æ¡ƒè¿”å›çš„éŸ³é¢‘\U0001F3B5")
                    # åˆ›å»º Image ç»„ä»¶å¹¶è®¾ç½®é»˜è®¤å›¾ç‰‡
                    image_box = gr.Image(label="èƒ¡æ¡ƒå¿ƒæƒ…å¯¹åº”çš„è¡¨æƒ…\U0001F60A",height = 200)

            # æŒ‰é’®è¢«ç‚¹å‡»æ—¶ï¼Œè°ƒç”¨ talk_with_hutao å‡½æ•°ï¼Œå¹¶å°†æ–‡æœ¬æ¡†çš„å†…å®¹å’ŒçŠ¶æ€å¯¹è±¡ä½œä¸ºå‚æ•°ï¼Œå°†å†å²è®°å½•æ–‡æœ¬æ¡†å’ŒéŸ³é¢‘æ’­æ”¾å™¨ä½œä¸ºè¾“å‡º
            button = gr.Button("å‘é€ \U0001F600")
            button.click(talk_with_hutao, [txt, state], [history_box, audio_box, image_box])

        with gr.Tab("è§‚å¯Ÿå’Œç®¡ç†èƒ¡æ¡ƒçš„Brainæ¨¡å—çŠ¶æ€ğŸ”§"):
            with gr.Row():
                with gr.Column():
                    agent_state = gr.Textbox(lines=25, max_lines=25, label="èƒ¡æ¡ƒçš„Brainæ¨¡å—çŠ¶æ€\U0001F4C4")
                    button = gr.Button("æŸ¥è¯¢ \U0001F600")
                    button.click(hutao.brain.show_info, inputs=[], outputs=agent_state)

                with gr.Column():
                    def del_memory(memory_index):
                        memory_str = ""
                        if isinstance(memory_index, int):
                            memory_str = hutao.brain.del_memory(mode="single", index=memory_index)
                            save_agent_json(hutao.brain)
                        if not memory_index:
                            memory_str = "ä¸‹æ‹‰èœå•ä¸ºç©ºæˆ–æ²¡æœ‰æ¥æ”¶åˆ°ä¸‹æ‹‰èœå•çš„å€¼"

                        memory_keys = list(range(len(hutao.brain.memory_stream)))
                        memory_dropdown = gr.Dropdown(memory_keys, label="è¦åˆ é™¤çš„è®°å¿†åºå·\U0001F600")

                        return memory_str, memory_dropdown

                    memory_keys = list(range(len(hutao.brain.memory_stream)))
                    memory_dropdown = gr.Dropdown(memory_keys, label="è¦åˆ é™¤çš„è®°å¿†åºå·\U0001F600")
                    memory_deleted = gr.Textbox(label="å·²åˆ é™¤çš„èƒ¡æ¡ƒè®°å¿†ğŸ§ ")
                    button = gr.Button("åˆ é™¤è®°å¿†ğŸ§Š")
                    button.click(fn=del_memory,
                                 inputs=memory_dropdown,
                                 outputs=[memory_deleted, memory_dropdown])

                    def del_knowledge(knowledge_index):
                        knowledge_str = ""
                        if isinstance(knowledge_index, int):
                            knowledge_str = hutao.brain.del_knowledge(mode="single", index=knowledge_index)
                            save_agent_json(hutao.brain)
                        if not knowledge_str:
                            knowledge_str = "ä¸‹æ‹‰èœå•ä¸ºç©ºæˆ–æ²¡æœ‰æ¥æ”¶åˆ°ä¸‹æ‹‰èœå•çš„å€¼"

                        knowledge_keys = list(range(len(hutao.brain.basic_knowledge)))
                        knowledge_dropdown = gr.Dropdown(knowledge_keys, label="è¦åˆ é™¤çš„çŸ¥è¯†åºå·\U0001F600,æ³¨æ„å­çŸ¥è¯†ä¹Ÿä¼šè¢«åˆ é™¤")

                        return knowledge_str, knowledge_dropdown

                    knowledge_keys = list(range(len(hutao.brain.basic_knowledge)))
                    knowledge_dropdown = gr.Dropdown(knowledge_keys, label="è¦åˆ é™¤çš„çŸ¥è¯†åºå·\U0001F600")
                    knowledge_deleted = gr.Textbox(label="å·²åˆ é™¤çš„èƒ¡æ¡ƒçŸ¥è¯†ğŸ“")
                    button = gr.Button("åˆ é™¤çŸ¥è¯†ğŸ§Š")
                    button.click(fn=del_knowledge,
                                 inputs=knowledge_dropdown,
                                 outputs=[knowledge_deleted, knowledge_dropdown])

        with gr.Tab("æ³¨å…¥ä¸€äº›çŸ¥è¯†\U0001F4D6"):
            def split_text_and_add_to_knowledge(content, summary_text):
                # è‹¥æºå†…å®¹è¿‡é•¿å°±å…ˆåˆ‡åˆ†
                max_unit_length = 500
                split = False

                # å¦‚æœ tokens æ•°é‡è¶…è¿‡äº†é™åˆ¶ï¼Œè¿›è¡Œåˆ‡åˆ†å¤„ç†
                if len(content) > max_unit_length:
                    split = True
                    knowledge_str = ""
                    segments = Perception.split_text(content,
                                                     min_length=max_unit_length,
                                                     buffer_min_length=int(max_unit_length*0.3))
                    knowledge_list = Perception.generate_knowledge_units(segments)
                    sub_knowledge_file = hutao.brain.add_knowledge_from_sub_knowledge_list(summary_text, knowledge_list)
                    knowledge_str += f"åŠ å…¥åˆ°çŸ¥è¯†åº“ä¸­çš„æ ¹çŸ¥è¯†ä¸º:{summary_text}\n\nå…¶å­çŸ¥è¯†æ–‡ä»¶è·¯å¾„ä¸º:{sub_knowledge_file}\n\n"
                    for idx, knowledge in enumerate(knowledge_list, 0):
                        knowledge_str += (f"çŸ¥è¯†å•å…ƒ{idx}\n"
                                          f"çŸ¥è¯†æè¿°:\n{knowledge['text']}\n"
                                          f"åµŒå…¥å‘é‡å¤§å°:{len(knowledge['embedding'])}\n"
                                          f"å­çŸ¥è¯†æ–‡ä»¶è·¯å¾„ï¼š{knowledge['sub_knowledge']}\n"
                                          f"{'-' * 40}\n")
                    save_agent_json(hutao.brain)

                    return knowledge_str, split

                else:
                    knowledge = hutao.brain.add_knowledge_from_text(content)
                    save_agent_json(hutao.brain)
                    knowledge_str = (f"çŸ¥è¯†æè¿°:\n{knowledge['text']}\n"
                                     f"åµŒå…¥å‘é‡å¤§å°:{len(knowledge['embedding'])}\n"
                                     f"ç”±äºè¾“å…¥çš„çŸ¥è¯†æ–‡æœ¬è¾ƒçŸ­ï¼Œæ²¡æœ‰å‘ç”Ÿåˆ‡åˆ†æˆ–äº§ç”Ÿå­çŸ¥è¯†æ–‡ä»¶\n"
                                     f"{'-' * 40}\n")

                    return knowledge_str, split

            def add_knowledge_from_webpage(webpage_content, summary_text):
                if not webpage_content:
                    return "è¯·è¾“å…¥è¦æ·»åŠ çš„çŸ¥è¯†å†…å®¹å“Ÿ"
                if not summary_text:
                    return "è¯·è¾“å…¥æ€»ç»“æ–‡æœ¬ï¼å®åœ¨éº»çƒ¦å°±å¤åˆ¶ä¸€ç‚¹~"
                # ä»é¡µé¢è¾“å…¥è·å¾—çŸ¥è¯†
                knowledge_str, split = split_text_and_add_to_knowledge(webpage_content, summary_text)

                if split:
                    webpage_str = (f"ä»é¡µé¢è¾“å…¥çš„å†…å®¹ä¸­è·å¾—äº†ä»¥ä¸‹çŸ¥è¯†:\n\n"
                                   f"ç”±äºçŸ¥è¯†æºæ–‡æœ¬è¿‡é•¿è€Œè¿›è¡Œäº†åˆ‡åˆ†,å¹¶ä»¥æ€»ç»“æ–‡æœ¬ä¸ºæ ¹ç”Ÿæˆäº†å­çŸ¥è¯†æ–‡ä»¶ï¼š\n\n{knowledge_str}")
                else:
                    webpage_str = (f"ä»é¡µé¢è¾“å…¥çš„å†…å®¹ä¸­è·å¾—äº†ä»¥ä¸‹çŸ¥è¯†:\n\n"
                                   f"\n\n{knowledge_str}")
                return webpage_str

            gr.Interface(fn=add_knowledge_from_webpage,
                         inputs=[gr.Textbox(label="ç›´æ¥è¾“å…¥çŸ¥è¯†æ–‡æœ¬ğŸ“"),
                                 gr.Textbox(label="è¾“å…¥çŸ¥è¯†æ–‡æœ¬çš„æ€»ç»“ğŸ“,è¿™å¯¹åˆ†å—ç´¢å¼•å¾ˆé‡è¦")],
                         outputs=gr.Textbox(label="ä»é¡µé¢è¾“å…¥ä¸­æå–åˆ°çš„çŸ¥è¯†ğŸ“"),
                         allow_flagging="never")

            def add_knowledge_from_pdf(pdf_path, summary_text):
                if not pdf_path:
                    return "è¯·ä¸Šä¼ PDFå“Ÿ"
                if not summary_text:
                    return "è¯·è¾“å…¥æ€»ç»“æ–‡æœ¬ï¼å®åœ¨éº»çƒ¦å°±å¤åˆ¶ä¸€ç‚¹~"
                # å¯¹pdfè¿›è¡Œåˆ‡åˆ†ï¼Œç›´æ¥åŠ è½½åˆ°çŸ¥è¯†åº“
                pdf_content = hutao.perception.read_pdf(pdf_path)
                pairs_str, split = split_text_and_add_to_knowledge(pdf_content, summary_text)

                if split:
                    pdf_str = (f"åŸºäºPDF:{pdf_path}åŠ è½½äº†å¦‚ä¸‹å†…å®¹:\n\n{pdf_content}"
                               f"\n\nç”±äºçŸ¥è¯†æºæ–‡æœ¬è¿‡é•¿è€Œè¿›è¡Œäº†åˆ‡åˆ†,å¹¶ä»¥æ€»ç»“æ–‡æœ¬ä¸ºæ ¹ç”Ÿæˆäº†å­çŸ¥è¯†æ–‡ä»¶ï¼š\n\n{pairs_str}")
                else:
                    pdf_str = (f"åŸºäºPDF:{pdf_path}åŠ è½½äº†å¦‚ä¸‹å†…å®¹:\n\n{pdf_content}"
                               f"\n\n{pairs_str}")
                return pdf_str

            gr.Interface(fn=add_knowledge_from_pdf,
                         inputs=[gr.File(label="ä¸Šä¼ PDFğŸ“"),
                                 gr.Textbox(label="è¾“å…¥çŸ¥è¯†æ–‡æœ¬çš„æ€»ç»“ğŸ“,è¿™å¯¹åˆ†å—ç´¢å¼•å¾ˆé‡è¦")],
                         outputs=gr.Textbox(label="ä»PDFæå–åˆ°çš„çŸ¥è¯†ğŸ“"),
                         allow_flagging="never")

            def add_knowledge_from_wiki(search_query, summary_text):
                if not search_query:
                    return "è¯·è¾“å…¥è¦æœç´¢çš„wikiå¯¹è±¡åå“Ÿ"
                if not summary_text:
                    return "è¯·è¾“å…¥æ€»ç»“æ–‡æœ¬ï¼å®åœ¨éº»çƒ¦å°±å¤åˆ¶ä¸€ç‚¹~"
                # è·å–wikiå†…å®¹
                wiki_object = hutao.action.use_wiki(search_query)
                wiki_url = wiki_object['url']
                wiki_content = wiki_object['content']
                pairs_str, split = split_text_and_add_to_knowledge(wiki_content, summary_text)

                if split:
                    wiki_str = (f"åŸºäºWikiçš„æŸ¥è¯¢:{search_query}\næ‰¾åˆ°äº†URL:{wiki_url},å†…å®¹å¦‚ä¸‹ï¼š"
                                f"\n\n{wiki_content}\n\nç”±äºçŸ¥è¯†æºæ–‡æœ¬è¿‡é•¿è€Œè¿›è¡Œäº†åˆ‡åˆ†,å¹¶ä»¥æ€»ç»“æ–‡æœ¬ä¸ºæ ¹ç”Ÿæˆäº†å­çŸ¥è¯†æ–‡ä»¶ï¼š\n\n{pairs_str}")
                else:
                    wiki_str = (f"åŸºäºWikiçš„æŸ¥è¯¢:{search_query}\næ‰¾åˆ°äº†URL:{wiki_url},å†…å®¹å¦‚ä¸‹ï¼š"
                                f"\n\n{wiki_content}\n\n{pairs_str}")
                return wiki_str

            gr.Interface(fn=add_knowledge_from_wiki,
                         inputs=[gr.Textbox(label="æœç´¢Wikiç™¾ç§‘ğŸ“"),
                                 gr.Textbox(label="è¾“å…¥çŸ¥è¯†æ–‡æœ¬çš„æ€»ç»“ğŸ“,è¿™å¯¹åˆ†å—ç´¢å¼•å¾ˆé‡è¦")],
                         outputs=gr.Textbox(label="ä»Wikiæå–åˆ°çš„çŸ¥è¯†ğŸ“"),
                         allow_flagging="never")

        with gr.Tab("ç®¡ç†å­çŸ¥è¯†æ–‡ä»¶\U0001F4D6"):
            sub_knowledge_list = Brain.get_all_sub_knowledge()
            summary_to_path_map = {item["sub_knowledge_summary_text"]: item["sub_knowledge_file_path"]
                                   for item in sub_knowledge_list}
            sub_knowledge_summary_text_list = list(summary_to_path_map.keys())
            sub_knowledge_dropdown = gr.Dropdown(label="å­çŸ¥è¯†æ–‡ä»¶åˆ—è¡¨ğŸ“", choices=sub_knowledge_summary_text_list)
            def show_sub_knowledge(summary_text):
                # ä½¿ç”¨æ€»ç»“æ–‡æœ¬æ¥æ‰¾æ–‡ä»¶
                if not summary_text:
                    return "ä¸‹æ‹‰èœå•ä¸ºç©ºæˆ–æ²¡æœ‰æ¥æ”¶åˆ°ä¸‹æ‹‰èœå•çš„å€¼"
                # ä½¿ç”¨æ˜ å°„æ¥æŸ¥æ‰¾å¯¹åº”çš„æ–‡ä»¶è·¯å¾„
                file_path = summary_to_path_map[summary_text]
                # è¯»å–æ–‡ä»¶å¹¶è¿”å›å†…å®¹
                return Brain.show_sub_knowledge(sub_knowledge_file=file_path)

            def add_knowledge_to_sub_knowledge_file(summary_text, knowledge_text):
                # ä½¿ç”¨æ€»ç»“æ–‡æœ¬æ¥æ‰¾æ–‡ä»¶
                if not summary_text:
                    return "ä¸‹æ‹‰èœå•ä¸ºç©ºæˆ–æ²¡æœ‰æ¥æ”¶åˆ°ä¸‹æ‹‰èœå•çš„å€¼"
                # ä½¿ç”¨æ˜ å°„æ¥æŸ¥æ‰¾å¯¹åº”çš„æ–‡ä»¶è·¯å¾„
                file_path = summary_to_path_map[summary_text]
                # æ·»åŠ çŸ¥è¯†
                return Brain.add_knowledge_to_sub_knowledge_file(file_path, knowledge_text)

            def del_knowledge_from_sub_knowledge_file(summary_text, del_knowledge_index):
                # ä½¿ç”¨æ€»ç»“æ–‡æœ¬æ¥æ‰¾æ–‡ä»¶
                if not summary_text:
                    return "ä¸‹æ‹‰èœå•ä¸ºç©ºæˆ–æ²¡æœ‰æ¥æ”¶åˆ°ä¸‹æ‹‰èœå•çš„å€¼"
                # ä½¿ç”¨æ˜ å°„æ¥æŸ¥æ‰¾å¯¹åº”çš„æ–‡ä»¶è·¯å¾„
                file_path = summary_to_path_map[summary_text]
                # åˆ é™¤çŸ¥è¯†
                try:
                    int(del_knowledge_index)
                except Exception as e:
                    return f"è¾“å…¥å†…å®¹æ— æ³•è½¬å‹ä¸ºä¸‹æ ‡ï¼Œè¯·è¾“å…¥æ•°å€¼"
                return Brain.del_knowledge_from_sub_knowledge_file(file_path, int(del_knowledge_index))

            with gr.Row():
                with gr.Column():
                    sub_knowledge_text = gr.Textbox(label="å­çŸ¥è¯†æ–‡ä»¶çš„å†…å®¹ğŸ“")
                    show_sub_knowledge_button = gr.Button(value="æµè§ˆå­çŸ¥è¯†å†…å®¹ğŸ“")
                    show_sub_knowledge_button.click(fn=show_sub_knowledge,
                                                    inputs=sub_knowledge_dropdown,
                                                    outputs=sub_knowledge_text)
                with gr.Column():
                    add_knowledge_text = gr.Textbox(label="ç»™å­çŸ¥è¯†æ–‡ä»¶æ·»åŠ çŸ¥è¯†ğŸ“š")
                    add_knowledge_button = gr.Button("æ·»åŠ çŸ¥è¯†ğŸ“š")
                    del_knowledge_index = gr.Textbox(label="åˆ é™¤å­çŸ¥è¯†æ–‡ä»¶çš„éƒ¨åˆ†çŸ¥è¯†ğŸ§Š")
                    del_knowledge_button = gr.Button("åˆ é™¤çŸ¥è¯†ğŸ§Š")

                    feedback_text = gr.Textbox(label="ç›¸å…³æ“ä½œçš„åé¦ˆğŸ“")
                    add_knowledge_button.click(fn=add_knowledge_to_sub_knowledge_file,
                                               inputs=[sub_knowledge_dropdown, add_knowledge_text],
                                               outputs=feedback_text)
                    del_knowledge_button.click(fn=del_knowledge_from_sub_knowledge_file,
                                               inputs=[sub_knowledge_dropdown, del_knowledge_index],
                                               outputs=feedback_text)


        with gr.Tab("å¸¸ç”¨çš„Prompts\U0001F4AD"):
            # åŠ è½½é¢„åˆ¶prompt
            def display_prompt(key: str) -> str:
                prompts = load_prompts("../resource/key_prompt.json")
                prompt = prompts.get(key, 'æ²¡æœ‰æ‰¾åˆ°å¯¹åº”çš„prompt')
                return prompt

            prompt_keys = load_prompts('../resource/key_prompt.json').keys()  # è·å–æ‰€æœ‰çš„key
            iface = gr.Interface(display_prompt,
                                 gr.Dropdown(prompt_keys, label="éœ€è¦çš„PromptåŠŸèƒ½ğŸŒ±"),
                                 gr.Textbox(label="é€šç”¨Promptå†…å®¹ğŸ’¬", show_copy_button = True),
                                 allow_flagging="never")

    demo.queue().launch(share=False)
